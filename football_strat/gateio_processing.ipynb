{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf266648-fcc9-42a6-a392-b0c513c52efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f0bea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"./gateio_data/major_trade_data\"\n",
    "files = [f for f in listdir(folder) if isfile(join(folder, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdcb5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#files = [i for i in files if i[6] in ['202307', '202308', '202309']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa66c23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f295a7b-ae35-46fc-a9c8-023a35f999fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_processing(df):\n",
    "    df = df[[\"timestamp\",\"dealid\",\"price\",\"amount\",\"side\"]]\n",
    "    df['hour'] = [i[:-3] for i in df['timestamp']]#.apply(lambda x: x.strftime('%Y-%m-%d-%H'))\n",
    "    df.set_index(\"hour\", inplace=True)\n",
    "    df.sort_values(by='timestamp', inplace=True)\n",
    "    return df\n",
    "\n",
    "def vwap1():\n",
    "    df = pd.DataFrame()\n",
    "    for each_file in files[:1]:\n",
    "            if each_file != \".DS_Store\":\n",
    "                #vwap calc based on https://school.stockcharts.com/doku.php?id=technical_indicators:vwap_intraday\n",
    "                tp = (each_file['price'].groupby(level=0).max()+each_file['price'].groupby(level=0).min()\n",
    "                    +each_file['price'].groupby(level=0).tail(1))/3\n",
    "                v = each_file['amount'].groupby(level=0).sum()\n",
    "                tp_v = tp*v\n",
    "                tp_v_cum = tp_v.cumsum()\n",
    "                v_cum = v.cumsum()\n",
    "                vwap = tp_v_cum/v_cum\n",
    "                new_df = pd.DataFrame(vwap)\n",
    "                new_df['ticker'] = each_file[:-7]\n",
    "                new_df.columns = ['vwap', 'ticker']\n",
    "                if df.empty:\n",
    "                    df = new_df\n",
    "                else: \n",
    "                    df = pd.concat([df, new_df])\n",
    "    #df.to_csv(\"./data/aggregated_trade_data.csv\")\n",
    "    return df\n",
    "\n",
    "def vwap_vanilla(df):\n",
    "    q = df.amount.values\n",
    "    p = df.price.values\n",
    "    return df.assign(vwap=(p * q).cumsum() / q.cumsum())\n",
    "\n",
    "def vwap2(df):\n",
    "    df = df.groupby(df.index.date, group_keys=False).apply(vwap_vanilla)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d872809-b62a-4f27-88ea-b5f0234a9486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def each_assetmonth_sort(each_assetmonth):\n",
    "    #read and sort each month of data\n",
    "    df = pd.read_csv(folder+\"/\"+each_assetmonth)\n",
    "    df = df[[\"timestamp\",\"dealid\",\"price\",\"amount\",\"side\"]]\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y-%m-%d-%H-%M')\n",
    "    df.sort_values('timestamp', inplace=True)\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    #calculate vwap\n",
    "    df = vwap2(df)\n",
    "    #assemble all assets and times together\n",
    "    df = df[['price', 'vwap']]\n",
    "    #df['vwap_pct_change'] = df['vwap'].pct_change()\n",
    "    #df['price_pct_change'] = df['price'].pct_change()\n",
    "    df['ticker'] = each_assetmonth[:-7]\n",
    "    return df\n",
    "\n",
    "batched_data =[]\n",
    "for files in \n",
    "for each_assetmonth in files:\n",
    "        if each_assetmonth != \".DS_Store\":\n",
    "              batched_data.append(each_assetmonth_sort(each_assetmonth))\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "# [i.split('-')[0] for i in files]\n",
    "# matching_files = [i for i in listdir(folder) if isfile(join(folder,i)) and \\\n",
    "#          'SFP_USDT' in i]\n",
    "# matching_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = pd.concat(batched_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2691ee-f094-4eed-a71c-336538d8f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df.to_csv(\"./gateio_data/majors_agg_trade_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45733167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specific processing\n",
    "#agg_df = pd.read_csv(\"/Users/aronnyberg/code/quanty2/gateio_data/btc_trade_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg_df = agg_df[agg_df['ticker'] ==\"BTC_USDT\"]\n",
    "agg_df['timestamp'] = pd.to_datetime(agg_df['timestamp'])\n",
    "agg_df.set_index('timestamp', inplace=True)\n",
    "agg_df = agg_df['vwap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf8bec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100000  # Number of data points per batch\n",
    "\n",
    "# Calculate the number of batches\n",
    "num_batches = len(agg_df) // batch_size\n",
    "\n",
    "# Initialize an empty list to store the batched data\n",
    "batched_data = []\n",
    "\n",
    "# Loop through the data and create batches\n",
    "for i in range(num_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = (i + 1) * batch_size\n",
    "    batch = agg_df.iloc[start_idx:end_idx]\n",
    "    # Here, you can perform any desired aggregation on the batch, e.g., sum, mean, etc.\n",
    "    batched_data.append(batch.pct_change().resample('T').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47106786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the batched data into a single DataFrame\n",
    "#daily_btc_rets = pd.concat(batched_data)\n",
    "daily_rets = pd.concat(batched_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d85ebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_rets = daily_rets.resample('T').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a34539",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_rets.cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(batched_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
